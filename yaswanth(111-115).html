<!DOCTYPE html>
<html>
    <body>
        <p>integrity, including who should have the right to access or view versus who should have
            the right to make entries or change data.
        </p>
        <p>
            We may also see a movement from electronic decision support to decision making to
autonomous active intervention, which will have significant implications for privacy and
security.
        </p>
        <p>
            We will also increasingly have to recognise that within our communities there will be a
spectrum of different needs and ability to participate in and benefit from these technological developments together with an increasing knowledge gap between those that
have and those that do not have the required technology to access the therapeutic
knowledge alliance.
        </p>
        <p>
            Should a health service spend limited resource on creating and maintaining complex email
or web based assessment or self management channels that the most deprived or in need
are least able to access? These complex systems may clearly be of benefit, but are
potentially of greatest benefit to those already most able to advocate for themselves and
access the resource. Subsequently we will need to continuously revisit the question of,
what are the needs of our community and how can we best met those needs with limited
resource? Should the more complex, resource intensive systems be provided on a user
pays or targeted basis? Should a health service focus largely on the channels most
accessible to most people, or the channels most appropriate for those sub groups with
the greatest levels of deprivation and identified need? When considering the Therapeutic Knowledge Alliance, as a whole and not just electronic channels, the wider security
issues of “integrity” and “availability” still need to be considered. Getting clinicians out
into deprived communities, making “available” an “interpersonal” rather than “electronic” channel in the therapeutic knowledge alliance may be the most effective way to
ensure data “integrity” and identify and address unmet needs.
        </p>
        <center><h2> Conclusions

        </h2></center>
        <hr>
        <p>
            Health information privacy and security is an area of at times, strongly held and diverse
perspectives. The focus of this chapter has not been on supporting or refuting a single
view, but introducing a range of perspectives (even if they challenge my innate clinician
bias) and argue for balance and shared understanding. Privacy risk is not a single simple
definable entity, but instead complex and multidimensional with quantitative and
qualitative perceptual aspects, dynamically changing over time as various factors along
the knowledge chain interact, change and possibly compete. Clinicians and patients and
the wider community of healthcare stakeholders may vary markedly in their perceptions
of privacy risk, particularly when compared to the sub-optimal care risk that may arise
from the non flow of health information.
        </p>
        <p>
            Knowledge management and data mining techniques, provide an opportunity to utilise
large clinical data repositories to identify trends and patterns and “risk”. This ability
to identify risk can be perceived as a double edged sword. It can be used positively to
promote or support further research and lead to changes in clinical processes and

        </p>
        <p>
            effective targeting of efficacious and cost efficient interventions; or could be used
negatively to discriminate with potential perceived consequences ranging from increased insurance premiums, to refusal of insurance and health cover, mortgages or
employment and the creation of an uninsurable, unemployable “underclass”, to fears
with regards to persecution from totalitarian regimes.
        </p>
        <p>
            Sporadic incidents or reports of illegal “hacking”, or privacy infringement of individual
patient records by healthcare workers out of carelessness, malice or pecuniary gain will
remain of concern. However as a community looking to the future, we should be possibly
more concerned for potential frequent legal and systematic uses of health information
that lead to discrimination by insurers, employers or indeed government agencies.
        </p>
        <p>
            Before designing “privacy” solutions it is important to be clear on privacy risks and
priorities (whether medico-legal concerns, deterring malicious access or use, or the
increase in patient trust) and how any solution will contribute to or deter from providing
better integrated information for better integrated care. Technical processes, such as
firewalls, restricted access and audit trails, can provide important physical and psychological deterrents to malicious use and psychological reassurance to patients. However
significant risk is likely to lie beyond the protection of our technological armour and
within the behaviour of end users.
        </p>
        <p>
            Pragmatic “privacy” solutions focused on end user behaviour can include making login
processes as fast and intuitive as possible, (decreasing behavioural drivers to leave selflogged in or to share logins), privacy training and clear censure processes for malicious
use.
        </p>
        <p>
            There is a need for shared zones or models of acceptance within our communities, with
regard to privacy risk, sub-optimal care risk and information flow. In building a shared
zone of acceptance, we need to appreciate the complex ambiguity of many aspects of
healthcare, and the non linear nature of the therapeutic knowledge alliance, and the need
to integrate patients and their supports within that alliance. Recognising the difficulties
of implementing change within the complex health system, we need to adopt an
incremental iterative S.A.F.E. (Table 2) stepping stone ,or building block approach
,reflecting on and learning from each intervention, and progressively adapting to our
changing context or understanding of that context.
        </p>
        <p>
            Within an environment of limited resource, we need to recognise the diminishing returns
or additional benefit we may receive for each unit of expenditure, and how individually
worthy needs may have to be balanced against each other for an optimal outcome for our
communities. Electronic developments may certainly assist with data confidentiality,
integrity and availability, but education and the “professionalisation” of all health
knowledge system users, (clinical, non-clinical staff, patients and supports), is possibly
more important.
        </p>
        <p>
            Clinicians and health services will increasingly need to “respect, value and protect”
health information if they are to maintain patient confidence, and the comprehensiveness
and integrity and validity of information volunteered by patients for entry into electronic
systems. However potentially of greater risk is not clinicians or health services’ use of
patient data or an electronic health knowledge management system , to carry out their
integral clinical, administrative, research and educational roles, but how much that data

        </p>
        <p>
            is respected, valued and protected within wider society. If the fears of discrimination and
creation of an uninsurable, unemployable underclass come to pass it will be the result
of individual and collective actions of all us. The simple individual action of for example
accepting cheaper insurance or health premiums as we are in a highly identifiable low risk
group, without at least recognising that our gain is someone’s loss; the collective action
of governments failing to legislate to protect against discrimination, and to provide a
safety net for those most vulnerable.
        </p>
        <p>
            Assessing or predicting the impact or future consequences of current actions will remain
an ongoing challenge for health knowledge management system developments. We may
certainly carry out Privacy Impact Assessments and risk benefit analysis, based on our
current knowledge and context. However, as a global community, it is likely that the
challenges of grasping the double-headed sword of electronic health knowledge management systems have only just begun.
        </p>
        <center><h2>References</h2></center>
        <hr>
        <p>
            Anderson, R. (1996). Clinical system security: Interim guidelines. <i>British Medical</i><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i>Journal</i> 312, 109-111.<br>
Ash, J.A., Berg, M. & Coiera E. (2004). Some unintended consequences of information<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;technology in health care: The nature of patient care information system-related<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;errors. <i>JAMIA. 11:104-112.</i> First published online as doi: 10.1197/jamia.M1471.<br>
Ash, J.A., Gorman, P.N., Seshadri, V. & Hersh, W.R. (2004). Computerized physician order<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entry in U.S. hospitals: Results of a 2002 survey. <i>JAMIA, 11, 95-99.</i> First published<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;online as doi:10.1197/jamia.M1427.<br>
Berger, R.G. & Kichak, J.P. (2004). Viewpoint paper: Computerized physician order entry:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Helpful or harmful? <i>JAMIA 2004, 11,</i> 100-103. Pre-Print published November 21,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2003; doi:10.1197/jamia.M1411.<br>
Black, E. (2001). <i>IBM and the Holocaust: The strategic alliance between Nazi Germany<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and America’s most powerful corporation.</i> New York: Crown Publishers.<br>
Coiera, E. & Clarke, R. (2003) “e-Consent”: The design and implementation of consumer<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;consent mechanisms in an electronic environment. <i>JAMIA, 11(2),</i> 129-140. Pre-Print<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;published March 1, 2004; doi:10.1197/jamia.M1480.<br>
Davis, L., Domm, J.A., Konikoff, M.R. & Miller, R.A. (1999). Attitudes of first year medical<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;students toward the confidentiality of computerised patient records. <i>JAMIA, 6</i>(1).<br>
Denley, I. & Weston Smith, S. (1999). Privacy in clinical information systems in secondary<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;care. <i>British Medical Journal, 318,</i> 1328-1331.<br>
Engel, G.L. (1977). The need for a new medical model: A challenge for biomedicine.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i>Science, 196 </i>(4286).<br>
Etymology Dictionary (2001). Retrieved March 2004 from <i>http://www.etymonline.com</i><br>
Gerritsen, T. (2001). <i>The surgeon. </i>London: Bantam Books.<br>
Goldberger, A.L. (1996). Non-linear dynamics for clinicians: Chaos Ttheory, fractals, and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;complexity at the bedside.<i> The Lancet, 347</i>(9011).<br>
Goldstein, W. (1999). Dynamically based psychotherapy: A contemporary overview.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i>Psychiatric Times, XVI</i>(7).<br>
Heeks, R., Mundy, D. & Salazar, A. (1999). Why health care information systems succeed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or fail. Information systems for public sector management. <i>Working Paper Series,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;paper no. 9.</i> Institute for Development Policy and Management, Manchester, UK.<br>
Kennedy, H. (2004). Stop taking uncivil liberties with DNA. <i>New Scientist,</i> 2439.<br>
Littlejohns, P., Wyatt, J.C. & Garvican, L. (2003). Evaluating computerised health<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;information systems: Hard lessons still to be learnt. <i>British Medical Journal, </i>326,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;860-863.<br>
Maslow, A.H. (1943). A theory of human motivation. <i>Psychological Review, 50,</i> 370-396.<br>
NHS Confidentiality Consultation (2003). FIPR (Foundation for Information Policy<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Research). Retrieved March 2004 from <i>http://www.cl.cam.ac.uk/users/rja14/</i><br>
NHS Information Authority (2002) Draft: National patient information sharing charter.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieved March 2004 from<i> http://www.nhsia.nhs.uk/confidentiality</i><br>
NHS Information Authority (2002). Share with care! People’s views on consent and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;confidentiality of patient information.<br>
Oncken III, W. (1999). Having initiative, executive excellence. <i>Provo, 16(9)</i>, 19.<br>
Orr, M. (2000). <i>Implementation of health information systems: Background literature<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;review.</i> MBA research dissertation, Southern Cross University.<br>
Plesk, P.E. & Greenhalgh, T. (2001). The challenge of complexity in health care. <i>British<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Medical Journal,</i> 323, 625-628.<br>
Roger Clarke’s Web site (n.d.). Online <i>http://www.anu.edu.au/people/Roger.Clarke/</i><br>
Ross Anderson’s Web site (2004). Online <i>http://www.cl.cam.ac.uk/users/rja14/</i><br>
Slane, B.H. (2002). In Forward to<i> Privacy impact assessment handbook.</i> Wellington, New<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zealand: Office of the Privacy Commissioner.<br>
Smith, R. (1996). What clinical information do doctors need? <i>British Medical Journal,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;313,</i> 1062-1068.<br>
Standards Australia (2001). Knowledge management: A framework for succeeding in the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;knowledge era. HB275.<br>
Standards Australia/Standards New Zealand (2001). Information technology – Code of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;practice for information security management, AS/NZS ISO/IEC 17799:2001.<br>
Sveiby, K-E. (2001). Knowledge management – Lessons from the pioneers. Online <i>http:/<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/www.sveiby.com/KM-lessons.doc</i><br>
Tang, P.C. (2000). An AMIA perspective on proposed regulation of privacy of health<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;information. <i>JAMIA, 7</i>(2).<br>
Wyatt, J. (2001). Top tips on knowledge management.<i> Clinical Governance Bulletin,</i><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2(3).<br>


        </p>
        <center><i><h1>Section II</i></h1><br>
            <br>
           <h1>Organisational,</h1> 
            <h1> Cultural and Regulatory</h1> 
            <h1> Aspects of Clinical</h1> 
            <h1> Knowledge Management</h1> 
            </h1></center>

    </body>
</html>
<style>
    body{
        margin-left:  275px;
    margin-right: 300px;
    }
hr{
    background-color: black;
    height:2px;
}
        
    
</style>